/root/quantum-secure-commerce/middleware/__init__.py
# middleware/__init__.py
"""Middleware exports"""
from .security import (
    SecurityMiddleware,
    JWTBearer,
    RateLimitMiddleware,
    security_middleware,
    rate_limit_middleware,
    jwt_bearer
)

__all__ = [
    'SecurityMiddleware',
    'JWTBearer',
    'RateLimitMiddleware',
    'security_middleware',
    'rate_limit_middleware',
    'jwt_bearer'
]
/root/quantum-secure-commerce/middleware/security.py
# middleware/security.py
"""
Security middleware for FastAPI
"""
from fastapi import Request, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
from services.auth_service import auth_service
from services.rate_limiter import rate_limiter
import logging

logger = logging.getLogger(__name__)

class SecurityMiddleware:
    """Security middleware for API protection"""
    
    async def __call__(self, request: Request, call_next):
        # Add security headers
        response = await call_next(request)
        
        # Security headers
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
        response.headers["Content-Security-Policy"] = "default-src 'self'"
        
        return response

class JWTBearer(HTTPBearer):
    """JWT Bearer token verification"""
    
    def __init__(self, auto_error: bool = True):
        super(JWTBearer, self).__init__(auto_error=auto_error)
    
    async def __call__(self, request: Request) -> Optional[Dict]:
        credentials: HTTPAuthorizationCredentials = await super().__call__(request)
        
        if credentials:
            if not credentials.scheme == "Bearer":
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="Invalid authentication scheme."
                )
            
            # Verify token
            user_data = auth_service.verify_token(credentials.credentials)
            
            if not user_data:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="Invalid or expired token."
                )
            
            return user_data
        else:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Invalid authorization code."
            )

class RateLimitMiddleware:
    """Rate limiting middleware"""
    
    async def __call__(self, request: Request, call_next):
        # Get client IP
        client_ip = request.client.host
        
        # Check rate limit
        allowed, remaining = rate_limiter.check_rate_limit(client_ip)
        
        if not allowed:
            raise HTTPException(
                status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                detail="Rate limit exceeded. Please try again later."
            )
        
        # Add rate limit headers
        response = await call_next(request)
        response.headers["X-RateLimit-Remaining"] = str(remaining)
        
        return response

# Initialize middleware
security_middleware = SecurityMiddleware()
rate_limit_middleware = RateLimitMiddleware()
jwt_bearer = JWTBearer()
/root/quantum-secure-commerce/models/__init__.py
Trống

/root/quantum-secure-commerce/monitoring/grafana/dashboards/dashboard.yml
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards

/root/quantum-secure-commerce/monitoring/grafana/dashboards/quantum-commerce.json
{
  "dashboard": {
    "title": "Quantum-Secure E-Commerce Dashboard",
    "panels": [
      {
        "title": "Quantum Signature Operations",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(crypto_operations_total{operation_type=\"sign\"}[5m])",
            "legendFormat": "Signatures/sec"
          }
        ]
      },
      {
        "title": "Signature Verification Success Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(crypto_operations_total{operation_type=\"verify\",status=\"success\"}[5m]) / rate(crypto_operations_total{operation_type=\"verify\"}[5m]) * 100",
            "legendFormat": "Success %"
          }
        ]
      },
      {
        "title": "Payment Processing",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(payments_total[5m])",
            "legendFormat": "{{status}}"
          }
        ]
      },
      {
        "title": "API Response Times",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      }
    ]
  }
}

/root/quantum-secure-commerce/monitoring/grafana/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

/root/quantum-secure-commerce/monitoring/grafana/provisioning/dashboards/dashboard.yml
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    options:
      path: /etc/grafana/provisioning/dashboards

/root/quantum-secure-commerce/monitoring/grafana/provisioning/dashboards/quantum-dashboard.json
{
  "dashboard": {
    "id": null,
    "title": "Quantum Commerce Monitoring",
    "tags": ["quantum", "commerce"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "API Status",
        "type": "stat",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "up{job=\"quantum-commerce-api\"}",
            "legendFormat": "API Status"
          }
        ]
      },
      {
        "id": 2,
        "title": "Request Rate",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "Requests/sec"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "10s",
    "version": 1
  }
}

/root/quantum-secure-commerce/monitoring/grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

/root/quantum-secure-commerce/monitoring/prometheus/alerts.yml
groups:
  - name: quantum_commerce_alerts
    rules:
      # API availability
      - alert: QuantumAPIDown
        expr: up{job="quantum-commerce-api"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Quantum Commerce API is down"
          description: "The quantum-secure API has been down for more than 1 minute"
      
      # High error rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

/root/quantum-secure-commerce/monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alerts.yml"

scrape_configs:
  - job_name: 'quantum-commerce-api'
    static_configs:
      - targets: ['host.docker.internal:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
    scrape_timeout: 5s
    
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
      
  # Optional: enable when postgres/redis exporters are running
  # - job_name: 'postgres'
  #   static_configs:
  #     - targets: ['postgres-exporter:9187']
  # 
  # - job_name: 'redis'
  #   static_configs:
  #     - targets: ['redis-exporter:9121']

/root/quantum-secure-commerce/monitoring/__init__.py
Trống
/root/quantum-secure-commerce/monitoring/health_check.py
# monitoring/health_check.py
"""Health check endpoints and system monitoring"""
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from datetime import datetime
import psutil
import redis
from typing import Dict, Any
from database import get_db, engine
from config.dev_config import SecurityConfig
from monitoring.metrics import system_health
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/health", tags=["health"])

class HealthChecker:
    """System health monitoring"""
    
    def __init__(self):
        self.checks = {
            'database': self._check_database,
            'redis': self._check_redis,
            'crypto': self._check_crypto,
            'disk': self._check_disk_space,
            'memory': self._check_memory
        }
    
    async def check_all(self) -> Dict[str, Any]:
        """Run all health checks"""
        results = {
            'status': 'healthy',
            'timestamp': datetime.utcnow().isoformat(),
            'checks': {}
        }
        
        for name, check_func in self.checks.items():
            try:
                results['checks'][name] = await check_func()
            except Exception as e:
                logger.error(f"Health check {name} failed: {e}")
                results['checks'][name] = {
                    'status': 'unhealthy',
                    'error': str(e)
                }
                results['status'] = 'degraded'
        
        # Update system health metric
        overall_health = 1 if results['status'] == 'healthy' else 0
        system_health.set(overall_health)
        
        return results
    
    async def _check_database(self) -> Dict[str, Any]:
        """Check database connectivity"""
        try:
            with engine.connect() as conn:
                result = conn.execute("SELECT 1").scalar()
                return {
                    'status': 'healthy' if result == 1 else 'unhealthy',
                    'response_time_ms': 10  # Mock for now
                }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    async def _check_redis(self) -> Dict[str, Any]:
        """Check Redis connectivity"""
        try:
            r = redis.from_url(SecurityConfig.REDIS_URL)
            r.ping()
            return {
                'status': 'healthy',
                'response_time_ms': 5
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    async def _check_crypto(self) -> Dict[str, Any]:
        """Check crypto systems"""
        try:
            from crypto import DilithiumSigner, IBESystem
            
            # Quick test
            signer = DilithiumSigner()
            ibe = IBESystem()
            
            return {
                'status': 'healthy',
                'dilithium': 'active',
                'ibe': 'active'
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    async def _check_disk_space(self) -> Dict[str, Any]:
        """Check disk space"""
        try:
            disk_usage = psutil.disk_usage('/')
            return {
                'status': 'healthy' if disk_usage.percent < 90 else 'warning',
                'used_percent': disk_usage.percent,
                'free_gb': disk_usage.free / (1024**3)
            }
        except Exception as e:
            return {
                'status': 'unknown',
                'error': str(e)
            }
    
    async def _check_memory(self) -> Dict[str, Any]:
        """Check memory usage"""
        try:
            memory = psutil.virtual_memory()
            return {
                'status': 'healthy' if memory.percent < 85 else 'warning',
                'used_percent': memory.percent,
                'available_gb': memory.available / (1024**3)
            }
        except Exception as e:
            return {
                'status': 'unknown',
                'error': str(e)
            }

# Initialize health checker
health_checker = HealthChecker()

@router.get("/")
async def health_check():
    """Basic health check"""
    return {
        'status': 'healthy',
        'service': 'Quantum Commerce API',
        'timestamp': datetime.utcnow().isoformat()
    }

@router.get("/live")
async def liveness_probe():
    """Kubernetes liveness probe"""
    return {'status': 'alive'}

@router.get("/ready")
async def readiness_probe(db: Session = Depends(get_db)):
    """Kubernetes readiness probe"""
    try:
        # Quick DB check
        db.execute(text("SELECT 1"))
        return {'status': 'ready'}
    except Exception as e:
        logger.error(f"Readiness check failed: {e}")
        return {'status': 'not_ready'}, 503

@router.get("/detailed")
async def detailed_health():
    """Detailed health check"""
    return await health_checker.check_all()
/root/quantum-secure-commerce/monitoring/metrics.py
"""Prometheus metrics for monitoring"""
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from functools import wraps
import time

# Define metrics
payment_counter = Counter(
    'payments_total', 
    'Total number of payments processed',
    ['status', 'payment_method']
)

payment_amount = Histogram(
    'payment_amount_usd',
    'Payment amounts in USD',
    buckets=(10, 50, 100, 500, 1000, 5000, 10000)
)

payment_duration = Histogram(
    'payment_processing_duration_seconds',
    'Time spent processing payments'
)

active_users = Gauge(
    'active_users_total',
    'Number of currently active users'
)

crypto_operations = Counter(
    'crypto_operations_total',
    'Cryptographic operations performed',
    ['operation_type', 'algorithm']
)

api_requests = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status_code']
)

api_request_duration = Histogram(
    'api_request_duration_seconds',
    'API request duration',
    ['method', 'endpoint']
)

# Database metrics
db_connections = Gauge('db_connections_active', 'Active database connections')
db_queries = Counter('db_queries_total', 'Total database queries', ['query_type'])

# System health
system_health = Gauge('system_health_status', 'System health status (1=healthy, 0=unhealthy)')

# Decorators for tracking
def track_payment_metrics(func):
    """Decorator to track payment metrics"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            # Assume result has status and amount attributes
            payment_counter.labels(
                status='success',
                payment_method=kwargs.get('payment_method', 'unknown')
            ).inc()
            if hasattr(result, 'amount'):
                payment_amount.observe(float(result.amount))
            return result
        except Exception as e:
            payment_counter.labels(
                status='failed',
                payment_method=kwargs.get('payment_method', 'unknown')
            ).inc()
            raise e
        finally:
            payment_duration.observe(time.time() - start_time)
    return wrapper

def track_api_request(method: str, endpoint: str):
    """Decorator to track API requests"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            status_code = 200
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                status_code = getattr(e, 'status_code', 500)
                raise
            finally:
                api_requests.labels(
                    method=method,
                    endpoint=endpoint,
                    status_code=status_code
                ).inc()
                api_request_duration.labels(
                    method=method,
                    endpoint=endpoint
                ).observe(time.time() - start_time)
        return wrapper
    return decorator

def track_crypto_operation(operation_type: str, algorithm: str):
    """Decorator to track cryptographic operations"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)
            crypto_operations.labels(
                operation_type=operation_type,
                algorithm=algorithm
            ).inc()
            return result
        return wrapper
    return decorator

# Initialize system health as healthy
system_health.set(1)

/root/quantum-secure-commerce/monitoring/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'quantum-commerce-api'
    static_configs:
      - targets: ['qc_api:8000']
    scrape_interval: 10s
    metrics_path: '/metrics'
    scheme: 'http'
    scrape_timeout: 10s
/root/quantum-secure-commerce/nginx/ssl
Trống 
/root/quantum-secure-commerce/nginx/nginx.conf
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    server {
        listen 80;
        server_name localhost;

        # Frontend
        location / {
            root /usr/share/nginx/html;
            try_files $uri $uri/ /index.html;
        }

        # API proxy
        location /api {
            proxy_pass http://api:8000;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_cache_bypass $http_upgrade;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        # Metrics endpoint
        location /metrics {
            proxy_pass http://api:8000/metrics;
        }
    }
}

/root/quantum-secure-commerce/nginx/nginx.prod.conf
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    upstream api {
        server api:8000;
    }
    
    server {
        listen 80;
        server_name localhost;

        # API proxy - strip /api prefix
        location /api/ {
            proxy_pass http://api/;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Frontend
        location / {
            root /usr/share/nginx/html;
            try_files $uri $uri/ /index.html;
        }
    }
}

/root/quantum-secure-commerce/scripts/api_with_metrics.py
#!/usr/bin/env python3
"""
API với Prometheus metrics working properly
"""
import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.responses import PlainTextResponse
from contextlib import asynccontextmanager
import logging
import time
import random

# Install prometheus_client if needed
try:
    from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
except ImportError:
    import subprocess
    import sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "prometheus-client"])
    from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===== PROMETHEUS METRICS =====
# API Metrics
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code']
)

api_request_duration = Histogram(
    'api_request_duration_seconds',
    'API request duration',
    ['method', 'endpoint']
)

# Quantum Crypto Metrics
quantum_signatures_total = Counter(
    'quantum_signatures_total',
    'Total quantum signatures created',
    ['algorithm', 'status']
)

quantum_verifications_total = Counter(
    'quantum_verifications_total',
    'Total signature verifications',
    ['algorithm', 'result']
)

ibe_encryptions_total = Counter(
    'ibe_encryptions_total',
    'Total IBE encryptions',
    ['algorithm', 'status']
)

# Payment Metrics
payments_total = Counter(
    'payments_total',
    'Total payments processed',
    ['status', 'currency']
)

payment_amount_histogram = Histogram(
    'payment_amount_usd',
    'Payment amounts in USD',
    buckets=(10, 50, 100, 500, 1000, 5000, 10000, float('inf'))
)

# Security Events
security_events_total = Counter(
    'security_events_total',
    'Security events',
    ['event_type', 'severity']
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("🚀 Starting Quantum Commerce API with Metrics")
    security_events_total.labels(event_type='startup', severity='info').inc()
    
    # Import crypto system
    try:
        from crypto.production_crypto import create_production_crypto
        app.state.crypto = create_production_crypto()
        logger.info("✅ Crypto system loaded")
        security_events_total.labels(event_type='crypto_loaded', severity='info').inc()
    except Exception as e:
        logger.warning(f"⚠️ Crypto system not available: {e}")
        app.state.crypto = None
    
    yield
    
    # Shutdown
    logger.info("🛑 Shutting down API")
    security_events_total.labels(event_type='shutdown', severity='info').inc()

# Create FastAPI app
app = FastAPI(
    title="Quantum Commerce API with Metrics",
    description="E-commerce API with Prometheus metrics",
    version="1.0.0",
    lifespan=lifespan
)

# Middleware để track requests
@app.middleware("http")
async def metrics_middleware(request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    # Record metrics
    duration = time.time() - start_time
    method = request.method
    endpoint = request.url.path
    status_code = response.status_code
    
    http_requests_total.labels(
        method=method,
        endpoint=endpoint,
        status_code=status_code
    ).inc()
    
    api_request_duration.labels(
        method=method,
        endpoint=endpoint
    ).observe(duration)
    
    return response

# ===== API ENDPOINTS =====

@app.get("/")
async def root():
    """Health check với metrics"""
    return {
        "message": "Quantum-Secure E-Commerce API",
        "status": "healthy",
        "crypto_ready": hasattr(app.state, 'crypto') and app.state.crypto is not None,
        "quantum_secure": True,
        "metrics_enabled": True
    }

@app.get("/metrics", response_class=PlainTextResponse)
async def metrics():
    """Prometheus metrics endpoint"""
    return generate_latest()

@app.post("/api/crypto/sign")
async def sign_transaction(transaction_data: dict):
    """Sign transaction với metrics tracking"""
    start_time = time.time()
    
    try:
        if hasattr(app.state, 'crypto') and app.state.crypto:
            # Real crypto signing
            signed = app.state.crypto['signer'].sign_transaction(transaction_data)
            algorithm = signed.get('algorithm', 'Dilithium3')
            
            # Record metrics
            quantum_signatures_total.labels(
                algorithm=algorithm,
                status='success'
            ).inc()
            
            logger.info(f"✅ Transaction signed with {algorithm}")
            
            return {
                "status": "success",
                "signed_transaction": signed,
                "quantum_secure": signed.get('quantum_secure', True),
                "algorithm": algorithm,
                "metrics_tracked": True
            }
        else:
            # Mock signing với metrics
            algorithm = "Dilithium3"
            mock_signed = {
                "signature": f"mock_sig_{random.randint(1000, 9999)}",
                "algorithm": algorithm,
                "quantum_secure": True,
                "data": transaction_data
            }
            
            quantum_signatures_total.labels(
                algorithm=algorithm,
                status='success'
            ).inc()
            
            return {
                "status": "success",
                "signed_transaction": mock_signed,
                "quantum_secure": True,
                "algorithm": algorithm,
                "metrics_tracked": True
            }
            
    except Exception as e:
        quantum_signatures_total.labels(
            algorithm='unknown',
            status='failed'
        ).inc()
        
        logger.error(f"❌ Signing failed: {e}")
        raise HTTPException(status_code=500, detail=f"Signing failed: {str(e)}")

@app.post("/api/crypto/verify")
async def verify_signature(signed_data: dict):
    """Verify signature với metrics"""
    algorithm = signed_data.get('algorithm', 'Dilithium3')
    
    try:
        if hasattr(app.state, 'crypto') and app.state.crypto:
            # Real verification
            verified = app.state.crypto['signer'].verify_signature(signed_data)
        else:
            # Mock verification
            verified = True
        
        # Record metrics
        quantum_verifications_total.labels(
            algorithm=algorithm,
            result='valid' if verified else 'invalid'
        ).inc()
        
        return {
            "status": "success", 
            "verified": verified,
            "algorithm": algorithm,
            "metrics_tracked": True
        }
        
    except Exception as e:
        quantum_verifications_total.labels(
            algorithm=algorithm,
            result='error'
        ).inc()
        raise HTTPException(status_code=500, detail=f"Verification failed: {str(e)}")

@app.post("/api/crypto/encrypt")
async def encrypt_data(data: dict):
    """Encrypt data với IBE metrics"""
    message = data.get('message', '')
    identity = data.get('identity', '')
    algorithm = "enhanced_ibe_aes_gcm"
    
    if not message or not identity:
        raise HTTPException(status_code=400, detail="Message and identity required")
    
    try:
        if hasattr(app.state, 'crypto') and app.state.crypto:
            # Real encryption
            encrypted = app.state.crypto['ibe'].encrypt_for_user(message, identity)
        else:
            # Mock encryption
            encrypted = {
                "ciphertext": f"encrypted_{random.randint(1000, 9999)}",
                "algorithm": algorithm,
                "security_level": "AES-256-GCM"
            }
        
        # Record metrics
        ibe_encryptions_total.labels(
            algorithm=algorithm,
            status='success'
        ).inc()
        
        return {
            "status": "success",
            "encrypted_data": encrypted,
            "algorithm": algorithm,
            "metrics_tracked": True
        }
        
    except Exception as e:
        ibe_encryptions_total.labels(
            algorithm=algorithm,
            status='failed'
        ).inc()
        raise HTTPException(status_code=500, detail=f"Encryption failed: {str(e)}")

@app.post("/api/payments/process")
async def process_payment(payment_data: dict):
    """Process payment với full metrics"""
    amount = payment_data.get('amount', 0)
    currency = payment_data.get('currency', 'USD')
    
    try:
        if amount <= 0:
            raise ValueError("Invalid amount")
        
        # Record payment metrics
        payments_total.labels(status='success', currency=currency).inc()
        payment_amount_histogram.observe(amount)
        
        # Sign payment transaction
        transaction = {
            "transaction_id": f"pay_{random.randint(100000, 999999)}",
            "amount": amount,
            "currency": currency,
            "timestamp": time.time()
        }
        
        # Sign với metrics
        if hasattr(app.state, 'crypto') and app.state.crypto:
            signed = app.state.crypto['signer'].sign_transaction(transaction)
            signature = signed.get('signature', '')[:50] + "..."
            
            quantum_signatures_total.labels(
                algorithm=signed.get('algorithm', 'Dilithium3'),
                status='success'
            ).inc()
        else:
            signature = f"mock_payment_sig_{random.randint(1000, 9999)}"
            quantum_signatures_total.labels(
                algorithm='Dilithium3',
                status='success'
            ).inc()
        
        logger.info(f"✅ Payment processed: {amount} {currency}")
        
        return {
            "status": "success",
            "payment_id": transaction["transaction_id"],
            "amount": amount,
            "currency": currency,
            "signature": signature,
            "quantum_secure": True,
            "metrics_tracked": True
        }
        
    except Exception as e:
        payments_total.labels(status='failed', currency=currency).inc()
        security_events_total.labels(event_type='payment_failure', severity='error').inc()
        raise HTTPException(status_code=500, detail=f"Payment failed: {str(e)}")

@app.get("/api/metrics/summary")
async def metrics_summary():
    """Summary metrics cho debugging"""
    return {
        "metrics_endpoint": "/metrics",
        "crypto_available": hasattr(app.state, 'crypto') and app.state.crypto is not None,
        "tracking": {
            "http_requests": "✅ Enabled",
            "quantum_signatures": "✅ Enabled", 
            "ibe_encryptions": "✅ Enabled",
            "payments": "✅ Enabled",
            "security_events": "✅ Enabled"
        },
        "prometheus": "http://localhost:9090",
        "grafana": "http://localhost:3030"
    }

if __name__ == "__main__":
    print("🚀 Starting API with Prometheus Metrics...")
    uvicorn.run(
        "api_with_metrics:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )

/root/quantum-secure-commerce/scripts/create_db.py
#!/usr/bin/env python3
"""Create database schema"""

import os
from sqlalchemy import create_engine, text

# Database URL
db_url = "postgresql://quantum_user:quantum_pass@localhost:5432/postgres"

# Create engine
engine = create_engine(db_url)

# Create database if not exists
with engine.connect() as conn:
    conn.execute(text("COMMIT"))  # Exit any transaction
    exists = conn.execute(
        text("SELECT 1 FROM pg_database WHERE datname = 'quantum_commerce'")
    ).fetchone()
    
    if not exists:
        conn.execute(text("CREATE DATABASE quantum_commerce"))
        print("✓ Database 'quantum_commerce' created")
    else:
        print("✓ Database 'quantum_commerce' already exists")

print("✓ Database setup completed!")
/root/quantum-secure-commerce/scripts/create_tables.py
#!/usr/bin/env python3
"""Create database tables"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import create_engine
from database.schema import Base

# Database URL
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://quantum_user:secure_password@localhost:5432/quantum_commerce"
)

def create_tables():
    """Create all tables"""
    engine = create_engine(DATABASE_URL)
    
    print("Creating tables...")
    Base.metadata.create_all(bind=engine)
    print("✓ Tables created successfully!")
    
    # List created tables
    print("\nCreated tables:")
    for table in Base.metadata.tables:
        print(f"  - {table}")

if __name__ == "__main__":
    create_tables()

/root/quantum-secure-commerce/scripts/key_rotation.py
# security/incident_response.py
"""
SECURITY INCIDENT RESPONSE SYSTEM
Tự động phát hiện và response các security incidents
"""
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from enum import Enum
import asyncio

logger = logging.getLogger(__name__)

class IncidentSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium" 
    HIGH = "high"
    CRITICAL = "critical"

class IncidentType(Enum):
    UNAUTHORIZED_ACCESS = "unauthorized_access"
    CRYPTO_ATTACK = "crypto_attack"
    DATA_BREACH = "data_breach"
    KEY_COMPROMISE = "key_compromise"
    REPLAY_ATTACK = "replay_attack"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    SUSPICIOUS_ACTIVITY = "suspicious_activity"
    SYSTEM_COMPROMISE = "system_compromise"

class SecurityIncident:
    """Security incident object"""
    
    def __init__(self, incident_type: IncidentType, severity: IncidentSeverity, 
                 description: str, source_ip: str = None, user_id: str = None):
        self.id = f"INC_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{hash(description) % 10000:04d}"
        self.incident_type = incident_type
        self.severity = severity
        self.description = description
        self.source_ip = source_ip
        self.user_id = user_id
        self.timestamp = datetime.utcnow()
        self.status = "open"
        self.response_actions = []
        self.resolved_at = None

class IncidentResponseSystem:
    """Automated security incident response"""
    
    def __init__(self):
        self.incidents = {}  # In production: use database
        self.response_rules = self._load_response_rules()
        self.notification_config = self._load_notification_config()
        
    def _load_response_rules(self) -> Dict[str, Any]:
        """Load automated response rules"""
        return {
            IncidentType.UNAUTHORIZED_ACCESS: {
                'auto_actions': ['block_ip', 'invalidate_sessions', 'alert_admin'],
                'escalation_time_minutes': 15,
                'requires_manual_review': True
            },
            IncidentType.CRYPTO_ATTACK: {
                'auto_actions': ['emergency_key_rotation', 'block_ip', 'alert_security_team'],
                'escalation_time_minutes': 5,
                'requires_manual_review': True
            },
            IncidentType.DATA_BREACH: {
                'auto_actions': ['isolate_systems', 'emergency_key_rotation', 'notify_authorities'],
                'escalation_time_minutes': 1,
                'requires_manual_review': True
            },
            IncidentType.KEY_COMPROMISE: {
                'auto_actions': ['emergency_key_rotation', 'invalidate_all_sessions', 'alert_security_team'],
                'escalation_time_minutes': 2,
                'requires_manual_review': True
            },
            IncidentType.REPLAY_ATTACK: {
                'auto_actions': ['block_ip', 'invalidate_session', 'alert_admin'],
                'escalation_time_minutes': 10,
                'requires_manual_review': False
            },
            IncidentType.RATE_LIMIT_EXCEEDED: {
                'auto_actions': ['temporary_ip_block', 'alert_admin'],
                'escalation_time_minutes': 30,
                'requires_manual_review': False
            }
        }
    
    def _load_notification_config(self) -> Dict[str, Any]:
        """Load notification configuration"""
        return {
            'security_team_email': ['security@quantum-commerce.com'],
            'admin_email': ['admin@quantum-commerce.com'],
            'slack_security_channel': '#security-alerts',
            'pagerduty_integration': True,
            'sms_alerts': ['+1234567890']  # For critical incidents
        }
    
    async def report_incident(self, incident_type: IncidentType, severity: IncidentSeverity,
                            description: str, context: Dict[str, Any] = None) -> SecurityIncident:
        """Report và process security incident"""
        
        # Create incident
        incident = SecurityIncident(
            incident_type=incident_type,
            severity=severity,
            description=description,
            source_ip=context.get('source_ip') if context else None,
            user_id=context.get('user_id') if context else None
        )
        
        # Store incident
        self.incidents[incident.id] = incident
        
        logger.critical(f"🚨 SECURITY INCIDENT: {incident.id} - {incident.incident_type.value}")
        logger.critical(f"   Severity: {incident.severity.value}")
        logger.critical(f"   Description: {incident.description}")
        
        # Trigger automated response
        await self._trigger_automated_response(incident, context)
        
        # Send notifications
        await self._send_incident_notifications(incident)
        
        return incident
    
    async def _trigger_automated_response(self, incident: SecurityIncident, context: Dict[str, Any] = None):
        """Trigger automated response actions"""
        
        rules = self.response_rules.get(incident.incident_type)
        if not rules:
            logger.warning(f"No response rules for {incident.incident_type.value}")
            return
        
        logger.warning(f"🤖 Triggering automated response for {incident.id}")
        
        for action in rules['auto_actions']:
            try:
                success = await self._execute_response_action(action, incident, context)
                
                incident.response_actions.append({
                    'action': action,
                    'timestamp': datetime.utcnow().isoformat(),
                    'success': success,
                    'automated': True
                })
                
                if success:
                    logger.info(f"✅ Executed response action: {action}")
                else:
                    logger.error(f"❌ Failed response action: {action}")
                    
            except Exception as e:
                logger.error(f"❌ Response action {action} failed: {e}")
    
    async def _execute_response_action(self, action: str, incident: SecurityIncident, 
                                     context: Dict[str, Any] = None) -> bool:
        """Execute specific response action"""
        
        try:
            if action == 'block_ip':
                return await self._block_ip(incident.source_ip)
            
            elif action == 'temporary_ip_block':
                return await self._temporary_ip_block(incident.source_ip, minutes=30)
            
            elif action == 'invalidate_sessions':
                return await self._invalidate_user_sessions(incident.user_id)
            
            elif action == 'invalidate_all_sessions':
                return await self._invalidate_all_sessions()
            
            elif action == 'emergency_key_rotation':
                return await self._emergency_key_rotation(incident.description)
            
            elif action == 'isolate_systems':
                return await self._isolate_affected_systems(context)
            
            elif action == 'alert_admin':
                return await self._alert_administrators(incident)
            
            elif action == 'alert_security_team':
                return await self._alert_security_team(incident)
            
            elif action == 'notify_authorities':
                return await self._notify_authorities(incident)
            
            else:
                logger.warning(f"Unknown response action: {action}")
                return False
                
        except Exception as e:
            logger.error(f"Response action {action} error: {e}")
            return False
    
    async def _block_ip(self, ip_address: str) -> bool:
        """Block IP address permanently"""
        if not ip_address:
            return False
        
        # In production: update firewall rules, WAF, etc.
        logger.warning(f"🚫 BLOCKING IP: {ip_address}")
        
        # Add to blocked IPs list
        from security.security_middleware import security_middleware
        security_middleware.suspicious_ips.add(ip_address)
        
        return True
    
    async def _temporary_ip_block(self, ip_address: str, minutes: int = 30) -> bool:
        """Temporarily block IP address"""
        if not ip_address:
            return False
        
        logger.warning(f"⏰ TEMPORARY BLOCK: {ip_address} for {minutes} minutes")
        
        # Implementation: temporary block logic
        # Could use Redis with TTL
        
        return True
    
    async def _invalidate_user_sessions(self, user_id: str) -> bool:
        """Invalidate all sessions for specific user"""
        if not user_id:
            return False
        
        logger.warning(f"🔓 INVALIDATING SESSIONS for user: {user_id}")
        
        try:
            from services.session_service import session_service
            count = session_service.destroy_all_user_sessions(int(user_id))
            logger.info(f"✅ Invalidated {count} sessions for user {user_id}")
            return True
        except Exception as e:
            logger.error(f"Session invalidation failed: {e}")
            return False
    
    async def _invalidate_all_sessions(self) -> bool:
        """Invalidate ALL active sessions (nuclear option)"""
        logger.critical("☢️  INVALIDATING ALL SESSIONS (NUCLEAR OPTION)")
        
        try:
            from services.session_service import session_service
            # Implementation: clear all session keys from Redis
            # session_service.redis_client.flushdb()
            
            logger.critical("✅ All sessions invalidated")
            return True
        except Exception as e:
            logger.error(f"Failed to invalidate all sessions: {e}")
            return False
    
    async def _emergency_key_rotation(self, reason: str) -> bool:
        """Emergency rotation of all cryptographic keys"""
        logger.critical(f"🔄 EMERGENCY KEY ROTATION: {reason}")
        
        try:
            from scripts.key_rotation import KeyRotationManager
            rotation_manager = KeyRotationManager()
            await rotation_manager.emergency_rotate_all_keys(reason)
            return True
        except Exception as e:
            logger.error(f"Emergency key rotation failed: {e}")
            return False
    
    async def _isolate_affected_systems(self, context: Dict[str, Any] = None) -> bool:
        """Isolate affected systems from network"""
        logger.critical("🏝️ ISOLATING AFFECTED SYSTEMS")
        
        # Implementation would:
        # 1. Identify affected containers/services
        # 2. Remove from load balancer
        # 3. Block network access
        # 4. Create isolated environment for forensics
        
        return True
    
    async def _alert_administrators(self, incident: SecurityIncident) -> bool:
        """Alert system administrators"""
        message = f"""
🚨 SECURITY ALERT - {incident.severity.value.upper()}

Incident ID: {incident.id}
Type: {incident.incident_type.value}
Time: {incident.timestamp}
Description: {incident.description}
Source IP: {incident.source_ip or 'N/A'}
User ID: {incident.user_id or 'N/A'}

Immediate actions taken:
{chr(10).join([f"- {action['action']}" for action in incident.response_actions])}

Please review and take additional action if needed.
        """
        
        # Send email/slack notifications
        await self._send_notification(message, self.notification_config['admin_email'])
        return True
    
    async def _alert_security_team(self, incident: SecurityIncident) -> bool:
        """Alert security team"""
        message = f"""
🚨 CRITICAL SECURITY INCIDENT

ID: {incident.id}
Severity: {incident.severity.value.upper()}
Type: {incident.incident_type.value}
Time: {incident.timestamp}

{incident.description}

Automated response triggered. Manual review required.
        """
        
        # Send to security team
        await self._send_notification(message, self.notification_config['security_team_email'])
        
        # Send SMS for critical incidents
        if incident.severity == IncidentSeverity.CRITICAL:
            await self._send_sms_alert(message)
        
        return True
    
    async def _notify_authorities(self, incident: SecurityIncident) -> bool:
        """Notify authorities for data breaches"""
        logger.critical("🏛️ NOTIFYING AUTHORITIES - DATA BREACH")
        
        # Implementation would:
        # 1. Prepare incident report
        # 2. Send to regulatory bodies (GDPR, etc.)
        # 3. Notify law enforcement if required
        # 4. Document all communications
        
        return True
    
    async def _send_notification(self, message: str, recipients: List[str]):
        """Send notification via email/slack"""
        logger.info(f"📨 Sending notification to {len(recipients)} recipients")
        # Implementation: actual email/slack sending
    
    async def _send_sms_alert(self, message: str):
        """Send SMS alert for critical incidents"""
        logger.info("📱 Sending SMS alert")
        # Implementation: SMS gateway integration
    
    async def _send_incident_notifications(self, incident: SecurityIncident):
        """Send notifications based on incident severity"""
        
        if incident.severity in [IncidentSeverity.CRITICAL, IncidentSeverity.HIGH]:
            await self._alert_security_team(incident)
        
        if incident.severity == IncidentSeverity.CRITICAL:
            # Page security team immediately
            logger.critical(f"📟 PAGING SECURITY TEAM - {incident.id}")
        
        # Always alert admins
        await self._alert_administrators(incident)
    
    def get_incident_statistics(self, days: int = 30) -> Dict[str, Any]:
        """Get incident statistics"""
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        
        recent_incidents = [
            inc for inc in self.incidents.values()
            if inc.timestamp >= cutoff_date
        ]
        
        stats = {
            'total_incidents': len(recent_incidents),
            'by_severity': {},
            'by_type': {},
            'resolved_count': 0,
            'avg_resolution_time_hours': 0
        }
        
        # Count by severity
        for severity in IncidentSeverity:
            count = len([inc for inc in recent_incidents if inc.severity == severity])
            stats['by_severity'][severity.value] = count
        
        # Count by type
        for incident_type in IncidentType:
            count = len([inc for inc in recent_incidents if inc.incident_type == incident_type])
            stats['by_type'][incident_type.value] = count
        
        # Resolution stats
        resolved = [inc for inc in recent_incidents if inc.resolved_at]
        stats['resolved_count'] = len(resolved)
        
        if resolved:
            total_resolution_time = sum([
                (inc.resolved_at - inc.timestamp).total_seconds() / 3600
                for inc in resolved
            ])
            stats['avg_resolution_time_hours'] = total_resolution_time / len(resolved)
        
        return stats
    
    async def resolve_incident(self, incident_id: str, resolution_notes: str):
        """Mark incident as resolved"""
        if incident_id in self.incidents:
            incident = self.incidents[incident_id]
            incident.status = "resolved"
            incident.resolved_at = datetime.utcnow()
            
            logger.info(f"✅ Incident {incident_id} resolved: {resolution_notes}")
            
            # Send resolution notification
            await self._send_resolution_notification(incident, resolution_notes)

    async def _send_resolution_notification(self, incident: SecurityIncident, notes: str):
        """Send incident resolution notification"""
        message = f"""
✅ INCIDENT RESOLVED

ID: {incident.id}
Type: {incident.incident_type.value}
Resolved: {incident.resolved_at}
Resolution: {notes}

Total duration: {incident.resolved_at - incident.timestamp}
        """
        
        await self._send_notification(message, self.notification_config['admin_email'])

# Global incident response system
incident_response = IncidentResponseSystem()

# Convenience functions for common incidents
async def report_unauthorized_access(source_ip: str, user_id: str = None, details: str = ""):
    """Report unauthorized access attempt"""
    return await incident_response.report_incident(
        IncidentType.UNAUTHORIZED_ACCESS,
        IncidentSeverity.HIGH,
        f"Unauthorized access attempt: {details}",
        {'source_ip': source_ip, 'user_id': user_id}
    )

async def report_crypto_attack(attack_type: str, source_ip: str = None, details: str = ""):
    """Report cryptographic attack"""
    return await incident_response.report_incident(
        IncidentType.CRYPTO_ATTACK,
        IncidentSeverity.CRITICAL,
        f"Crypto attack detected: {attack_type} - {details}",
        {'source_ip': source_ip}
    )

async def report_data_breach(affected_users: int, data_types: List[str], details: str = ""):
    """Report data breach"""
    return await incident_response.report_incident(
        IncidentType.DATA_BREACH,
        IncidentSeverity.CRITICAL,
        f"Data breach: {affected_users} users affected, data: {', '.join(data_types)} - {details}",
        {'affected_users': affected_users, 'data_types': data_types}
    )

# CLI for incident management
async def main():
    """CLI for incident management"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Security Incident Response')
    parser.add_argument('action', choices=['list', 'stats', 'resolve', 'test'])
    parser.add_argument('--incident-id', help='Incident ID for resolution')
    parser.add_argument('--notes', help='Resolution notes')
    parser.add_argument('--days', type=int, default=30, help='Days for statistics')
    
    args = parser.parse_args()
    
    if args.action == 'list':
        print("🚨 RECENT SECURITY INCIDENTS")
        print("=" * 60)
        
        recent_incidents = sorted(
            incident_response.incidents.values(),
            key=lambda x: x.timestamp,
            reverse=True
        )[:10]
        
        for incident in recent_incidents:
            print(f"\n{incident.id}")
            print(f"  Type: {incident.incident_type.value}")
            print(f"  Severity: {incident.severity.value}")
            print(f"  Time: {incident.timestamp}")
            print(f"  Status: {incident.status}")
            print(f"  Description: {incident.description}")
            if incident.source_ip:
                print(f"  Source IP: {incident.source_ip}")
            print(f"  Actions: {len(incident.response_actions)} automated")
    
    elif args.action == 'stats':
        print("📊 INCIDENT STATISTICS")
        print("=" * 40)
        
        stats = incident_response.get_incident_statistics(args.days)
        
        print(f"Last {args.days} days:")
        print(f"Total incidents: {stats['total_incidents']}")
        print(f"Resolved: {stats['resolved_count']}")
        print(f"Avg resolution time: {stats['avg_resolution_time_hours']:.1f} hours")
        
        print("\nBy Severity:")
        for severity, count in stats['by_severity'].items():
            print(f"  {severity}: {count}")
        
        print("\nBy Type:")
        for incident_type, count in stats['by_type'].items():
            if count > 0:
                print(f"  {incident_type}: {count}")
    
    elif args.action == 'resolve':
        if not args.incident_id or not args.notes:
            print("❌ Incident ID and resolution notes required")
            return
        
        await incident_response.resolve_incident(args.incident_id, args.notes)
        print(f"✅ Incident {args.incident_id} marked as resolved")
    
    elif args.action == 'test':
        print("🧪 TESTING INCIDENT RESPONSE SYSTEM")
        print("=" * 50)
        
        # Test different incident types
        test_incidents = [
            (IncidentType.RATE_LIMIT_EXCEEDED, IncidentSeverity.LOW, "Test rate limit"),
            (IncidentType.UNAUTHORIZED_ACCESS, IncidentSeverity.HIGH, "Test unauthorized access"),
            (IncidentType.CRYPTO_ATTACK, IncidentSeverity.CRITICAL, "Test crypto attack")
        ]
        
        for incident_type, severity, description in test_incidents:
            incident = await incident_response.report_incident(
                incident_type, severity, description,
                {'source_ip': '192.168.1.100', 'user_id': 'test_user'}
            )
            print(f"✅ Created test incident: {incident.id}")
            
            # Auto-resolve test incidents
            await incident_response.resolve_incident(incident.id, "Test incident - auto resolved")

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
/root/quantum-secure-commerce/scripts/quick_dev_setup.sh
#!/bin/bash
# Quick Development Setup - Skip production secrets

echo "🚀 QUICK DEVELOPMENT SETUP"
echo "=========================="

# 1. Create .env for development
cat > .env << 'EOF'
# DEVELOPMENT ENVIRONMENT
APP_NAME=quantum-commerce
APP_ENV=development
DEBUG=true

# Skip production secrets
USE_REAL_CRYPTO=false
USE_ENCRYPTED_SECRETS=false

# Database - Match docker containers
DB_HOST=localhost
DB_PORT=5432
DB_USER=quantum_user
DB_PASSWORD=quantum_secure_pass_123
DB_NAME=quantum_commerce

# Redis - Match docker containers
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=redis_secure_pass_456

# Vault
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=dev_vault_token_789

# Development master password (any value)
MASTER_PASSWORD=test_master_key_123

# Features
RATE_LIMIT_ENABLED=true
SESSION_TIMEOUT_MINUTES=30

# Monitoring
PROMETHEUS_HOST=localhost
PROMETHEUS_PORT=9090
GRAFANA_HOST=localhost  
GRAFANA_PORT=3030
GRAFANA_PASSWORD=quantum_admin_123
EOF

echo "✅ Created .env for development"

# 2. Set environment
export MASTER_PASSWORD=test_master_key_123
export APP_ENV=development
export USE_REAL_CRYPTO=false

echo "✅ Environment variables set"

# 3. Fix encryption error
# if [ -f "database/encryption.py" ]; then
#     sed -i 's/SecurityConfig.get_fernet_key()()/SecurityConfig.get_fernet_key()/g' database/encryption.py
#     echo "✅ Fixed encryption.py"
# fi

# 4. Test database connection
echo "🔍 Testing database connection..."
python3 -c "
import psycopg2
try:
    conn = psycopg2.connect(
        host='localhost', port=5432,
        user='quantum_user', 
        password='quantum_secure_pass_123',
        database='quantum_commerce'
    )
    print('✅ PostgreSQL: Connected!')
    conn.close()
except Exception as e:
    print(f'❌ PostgreSQL: {e}')
"

# 5. Test Redis
echo "🔍 Testing Redis connection..."
python3 -c "
import redis
try:
    r = redis.Redis(host='localhost', port=6379, password='redis_secure_pass_456')
    r.ping()
    print('✅ Redis: Connected!')
except Exception as e:
    print(f'❌ Redis: {e}')
"

# 6. Test imports
echo "🔍 Testing module imports..."
python3 -c "
try:
    from database.schema import Base
    print('✅ Database schema: OK')
except Exception as e:
    print(f'❌ Schema import: {e}')
"

echo ""
echo "🎉 DEVELOPMENT SETUP COMPLETE!"
echo ""
echo "📋 NEXT STEPS:"
echo "1. python scripts/create_tables.py"
echo "2. python main.py"
echo ""
echo "🌐 Access points:"
echo "- API: http://localhost:8000"
echo "- Docs: http://localhost:8000/docs"
/root/quantum-secure-commerce/scripts/recreate_tables.py
#!/usr/bin/env python3
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import create_engine, text
from database.schema import Base

DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://quantum_user:secure_password@localhost:5432/quantum_commerce"
)

engine = create_engine(DATABASE_URL)

print("Dropping all tables...")
with engine.connect() as conn:
    conn.execute(text("DROP TABLE IF EXISTS audit_logs CASCADE"))
    conn.execute(text("DROP TABLE IF EXISTS receipts CASCADE"))
    conn.execute(text("DROP TABLE IF EXISTS transactions CASCADE"))
    conn.execute(text("DROP TABLE IF EXISTS crypto_keys CASCADE"))
    conn.execute(text("DROP TABLE IF EXISTS users CASCADE"))
    conn.commit()
    print("✓ Tables dropped")

print("Creating new tables...")
Base.metadata.create_all(bind=engine)
print("✓ Tables created successfully!")

# List tables
with engine.connect() as conn:
    result = conn.execute(text("""
        SELECT tablename FROM pg_tables 
        WHERE schemaname = 'public'
    """))
    print("\nCreated tables:")
    for row in result:
        print(f"  - {row[0]}")

/root/quantum-secure-commerce/scripts/setup_prod_secrets.py
#!/usr/bin/env python3
"""
PRODUCTION SECRET SETUP - SECURE KEY MANAGEMENT
Tạo và quản lý secrets an toàn cho production
setup_prodution_secrets.py
"""
import os
import json
import base64
import secrets
from pathlib import Path
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

class ProductionSecretManager:
    """Quản lý secrets cho production environment"""
    
    def __init__(self):
        self.secrets_dir = Path("secrets")
        self.secrets_dir.mkdir(exist_ok=True)
        
        # Bảo vệ thư mục secrets
        os.chmod(self.secrets_dir, 0o700)
        
    def generate_master_key(self) -> bytes:
        """Tạo master key từ password"""
        print("🔐 THIẾT LẬP MASTER KEY PRODUCTION")
        print("=" * 50)
        
        # Lấy master password từ người dùng
        master_password = os.getenv("MASTER_PASSWORD")
        if not master_password:
            master_password = input("Nhập MASTER_PASSWORD (sẽ lưu trong ENV): ")
            print("\n⚠️  LƯU MASTER_PASSWORD VÀO ENVIRONMENT VARIABLE:")
            print(f"export MASTER_PASSWORD='{master_password}'")
            print("hoặc thêm vào .env file (KHÔNG commit .env!)")
        
        # Tạo salt ngẫu nhiên
        salt = os.urandom(16)
        
        # Derive key với PBKDF2
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,  # 100k iterations cho security
        )
        
        key = base64.urlsafe_b64encode(kdf.derive(master_password.encode()))
        
        # Lưu salt
        salt_file = self.secrets_dir / "salt.dat"
        with open(salt_file, "wb") as f:
            f.write(salt)
        os.chmod(salt_file, 0o600)
        
        print(f"✅ Master key generated với 100,000 PBKDF2 iterations")
        print(f"✅ Salt saved to {salt_file}")
        
        return key
    
    def create_production_secrets(self):
        """Tạo tất cả secrets cần thiết cho production"""
        print("\n🔑 TẠO PRODUCTION SECRETS")
        print("=" * 40)
        
        # Generate master key
        master_key = self.generate_master_key()
        fernet = Fernet(master_key)
        
        # Generate secure secrets
        secrets_to_create = {
            'jwt_secret': base64.b64encode(secrets.token_bytes(32)).decode(),
            'dilithium_master_key': base64.b64encode(secrets.token_bytes(64)).decode(),
            'ibe_master_key': base64.b64encode(secrets.token_bytes(32)).decode(),
            'database_encryption_key': base64.b64encode(secrets.token_bytes(32)).decode(),
            'database_password': self._generate_secure_password(16),
            'redis_password': self._generate_secure_password(12),
        }
        
        # Encrypt và lưu secrets
        encrypted_secrets = {}
        for key, value in secrets_to_create.items():
            encrypted_value = fernet.encrypt(value.encode()).decode()
            encrypted_secrets[key] = encrypted_value
            print(f"✅ Generated: {key}")
        
        # Lưu encrypted secrets file
        secrets_file = self.secrets_dir / "encrypted_secrets.json"
        with open(secrets_file, "w") as f:
            json.dump(encrypted_secrets, f, indent=2)
        os.chmod(secrets_file, 0o600)
        
        print(f"\n✅ Encrypted secrets saved to {secrets_file}")
        print(f"🔒 File permissions: 600 (owner only)")
        
        return encrypted_secrets
    
    def _generate_secure_password(self, length: int) -> str:
        """Tạo password mạnh"""
        import string
        alphabet = string.ascii_letters + string.digits + "!@#$%^&*"
        return ''.join(secrets.choice(alphabet) for _ in range(length))
    
    def validate_secrets(self):
        """Kiểm tra tất cả secrets có tồn tại không"""
        print("\n🔍 KIỂM TRA SECRETS")
        print("=" * 30)
        
        required_secrets = [
            'jwt_secret',
            'dilithium_master_key', 
            'ibe_master_key',
            'database_encryption_key',
            'database_password',
            'redis_password'
        ]
        
        from services.secret_manager import secret_manager
        
        missing = []
        for secret in required_secrets:
            value = secret_manager.get_secret(secret)
            if value:
                print(f"✅ {secret}: {'*' * 20}")
            else:
                print(f"❌ {secret}: MISSING")
                missing.append(secret)
        
        if missing:
            print(f"\n⚠️  THIẾU SECRETS: {missing}")
            return False
        else:
            print(f"\n🎉 TẤT CẢ SECRETS ĐÃ SẴN SÀNG!")
            return True
    
    def setup_gitignore(self):
        """Tạo .gitignore để bảo vệ secrets"""
        gitignore_content = """
# SECRETS - KHÔNG BAO GIỜ COMMIT!
secrets/
.env
.env.local
.env.production
*.key
*.pem

# Crypto keys
keys/dilithium/
keys/ibe/
dilithium_*.key
ibe_*.key

# Database
*.db
*.sqlite

# Logs có thể chứa sensitive data
logs/
*.log

# Docker secrets
docker-compose.override.yml
.docker/

# Backup files
*.bak
*.backup
"""
        
        gitignore_file = Path(".gitignore")
        if gitignore_file.exists():
            with open(gitignore_file, "a") as f:
                f.write(gitignore_content)
        else:
            with open(gitignore_file, "w") as f:
                f.write(gitignore_content)
        
        print("✅ Updated .gitignore để bảo vệ secrets")
    
    def production_deployment_guide(self):
        """Hướng dẫn deploy production"""
        print("\n🚀 HƯỚNG DẪN DEPLOY PRODUCTION")
        print("=" * 50)
        
        guide = """
1. 🔐 THIẾT LẬP SECRETS:
   - Set MASTER_PASSWORD trong environment
   - Copy secrets/ folder lên server (SCP/SFTP)
   - chmod 700 secrets/
   - chmod 600 secrets/*

2. 🛡️  PRODUCTION ENVIRONMENT:
   export APP_ENV=production
   export MASTER_PASSWORD='your_secure_master_password'
   export USE_REAL_CRYPTO=true

3. 🗄️  DATABASE SETUP:
   - Tạo PostgreSQL database
   - Set DB_PASSWORD từ secrets
   - Run migrations: python scripts/create_tables.py

4. 🔧 INFRASTRUCTURE:
   - Setup HashiCorp Vault cho enterprise
   - Configure HSM nếu có
   - Setup load balancer
   - Configure monitoring

5. 🚀 DEPLOYMENT:
   docker-compose -f docker-compose.production.yml up -d

6. ✅ VERIFY:
   python scripts/test_real_crypto.py
   curl http://localhost:8000/api/crypto/status
        """
        
        print(guide)

if __name__ == "__main__":
    print("🛡️  QUANTUM-SECURE E-COMMERCE")
    print("🔐 PRODUCTION SECRET MANAGER")
    print("=" * 60)
    
    manager = ProductionSecretManager()
    
    # Setup menu
    while True:
        print("\nTùy chọn:")
        print("1. 🔑 Tạo production secrets")
        print("2. 🔍 Kiểm tra secrets hiện tại")
        print("3. 📝 Setup .gitignore")
        print("4. 📋 Hướng dẫn deployment")
        print("5. 🚪 Thoát")
        
        choice = input("\nChọn (1-5): ").strip()
        
        if choice == "1":
            manager.create_production_secrets()
            manager.setup_gitignore()
        elif choice == "2":
            manager.validate_secrets()
        elif choice == "3":
            manager.setup_gitignore()
        elif choice == "4":
            manager.production_deployment_guide()
        elif choice == "5":
            print("👋 Bye!")
            break
        else:
            print("❌ Lựa chọn không hợp lệ")
/root/quantum-secure-commerce/scripts/setup_production_secrets.py
# scripts/setup_production_secrets.py
"""
PRODUCTION SECRET SETUP - KHÔNG BAO GIỜ commit file này
Chạy 1 lần duy nhất để setup secrets, sau đó XÓA
"""
import os
import base64
import secrets
from pathlib import Path
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

class ProductionSecretSetup:
    """Setup secrets cho production - CHỈ CHẠY 1 LẦN"""
    
    def __init__(self):
        self.secrets_dir = Path("secrets")
        self.secrets_dir.mkdir(mode=0o700, exist_ok=True)
        
        # ĐỌC master password từ KEYBOARD (không lưu file)
        self.master_password = input("Nhập MASTER PASSWORD (nhớ kỹ, không lưu đâu): ").encode()
        
        # Tạo encryption key từ password
        salt = os.urandom(16)
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        
        self.key = base64.urlsafe_b64encode(kdf.derive(self.master_password))
        self.fernet = Fernet(self.key)
        
        # Lưu salt (cần để decrypt sau này)
        with open(self.secrets_dir / "salt.dat", "wb") as f:
            f.write(salt)
        os.chmod(self.secrets_dir / "salt.dat", 0o600)
    
    def generate_crypto_keys(self):
        """Tạo REAL crypto keys"""
        print("🔑 Generating cryptographic keys...")
        
        # 1. JWT Secret (256-bit)
        jwt_secret = base64.b64encode(secrets.token_bytes(32)).decode()
        
        # 2. Dilithium Master Key (512-bit for high security)
        dilithium_key = base64.b64encode(secrets.token_bytes(64)).decode()
        
        # 3. IBE Master Key (256-bit)
        ibe_key = base64.b64encode(secrets.token_bytes(32)).decode()
        
        # 4. Database encryption key
        db_key = base64.b64encode(secrets.token_bytes(32)).decode()
        
        # 5. Redis password
        redis_pass = secrets.token_urlsafe(32)
        
        # 6. Database password  
        db_pass = secrets.token_urlsafe(24)
        
        return {
            "jwt_secret": jwt_secret,
            "dilithium_master_key": dilithium_key,
            "ibe_master_key": ibe_key,
            "database_encryption_key": db_key,
            "redis_password": redis_pass,
            "database_password": db_pass,
        }
    
    def encrypt_and_store_secrets(self, secrets_dict):
        """Mã hóa và lưu secrets"""
        print("🔒 Encrypting and storing secrets...")
        
        encrypted_secrets = {}
        for key, value in secrets_dict.items():
            encrypted_value = self.fernet.encrypt(value.encode()).decode()
            encrypted_secrets[key] = encrypted_value
        
        # Lưu vào file mã hóa
        import json
        with open(self.secrets_dir / "encrypted_secrets.json", "w") as f:
            json.dump(encrypted_secrets, f, indent=2)
        
        os.chmod(self.secrets_dir / "encrypted_secrets.json", 0o600)
        
        print("✅ Secrets encrypted and stored safely")
    
    def create_env_template(self):
        """Tạo .env template KHÔNG chứa secrets"""
        template = """# .env.production
# PRODUCTION ENVIRONMENT - NO SECRETS HERE!
# All secrets are stored encrypted in secrets/ directory

# Application Config
APP_NAME=quantum-commerce
APP_ENV=production
DEBUG=false

# Database Connection (passwords stored encrypted)
DB_HOST=postgres
DB_PORT=5432
DB_NAME=quantum_commerce
DB_USER=quantum_user

# Redis Connection  
REDIS_HOST=redis
REDIS_PORT=6379

# Vault Config
VAULT_ADDR=http://vault:8200

# Feature Flags
USE_REAL_CRYPTO=true
RATE_LIMIT_ENABLED=true
SESSION_TIMEOUT_MINUTES=30

# Monitoring
PROMETHEUS_PORT=9090
GRAFANA_PORT=3030

# ⚠️ SECRETS ĐƯỢC LẤY TỪ ENCRYPTED STORAGE
# KHÔNG BAO GIỜ commit passwords vào đây!
"""
        
        with open(".env.production", "w") as f:
            f.write(template)
        
        print("📝 Created .env.production template")
    
    def setup_gitignore(self):
        """Cập nhật .gitignore để bảo vệ secrets"""
        gitignore_additions = """
# SECURITY - NEVER COMMIT THESE!
secrets/
.env
.env.local
.env.production
.env.development
*.key
*.pem
master_password.txt
vault_token.txt

# Crypto keys
keys/dilithium/
keys/ibe/
keys/*.key

# Logs có thể chứa sensitive data
logs/*.log
logs/security.log

# Database dumps
*.sql
*.db

# Backup files
*.backup
*.bak
temp/
"""
        
        with open(".gitignore", "a") as f:
            f.write(gitignore_additions)
        
        print("🛡️ Updated .gitignore for security")
    
    def run_setup(self):
        """Chạy toàn bộ setup"""
        print("🚀 PRODUCTION SECRET SETUP")
        print("=" * 50)
        
        # 1. Generate keys
        secrets_dict = self.generate_crypto_keys()
        
        # 2. Encrypt and store
        self.encrypt_and_store_secrets(secrets_dict)
        
        # 3. Create templates
        self.create_env_template()
        
        # 4. Setup gitignore
        self.setup_gitignore()
        
        print("\n✅ SETUP COMPLETE!")
        print("🔑 Secrets stored encrypted in secrets/")
        print("⚠️  NHỚ MASTER PASSWORD - không có cách nào recover!")
        print("📝 Sử dụng .env.production template")
        
        # Hiển thị hướng dẫn
        print("\n📋 NEXT STEPS:")
        print("1. Export MASTER_PASSWORD environment variable")
        print("2. rm scripts/setup_production_secrets.py  # XÓA FILE NÀY!")
        print("3. git add .gitignore")
        print("4. git commit -m 'Add security .gitignore'")
        print("5. KHÔNG BAO GIỜ commit secrets/")

if __name__ == "__main__":
    setup = ProductionSecretSetup()
    setup.run_setup()
/root/quantum-secure-commerce/scripts/setup_secrets.py
#!/usr/bin/env python3
"""
Setup secrets securely - RUN ONCE sau khi deploy
"""
import sys
import getpass
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.secret_manager import secret_manager

def setup_production_secrets():
    """Setup secrets cho production"""
    print("🔐 Quantum Commerce - Secret Setup")
    print("=" * 40)
    
    # Yêu cầu user nhập passwords
    secrets = {}
    
    print("\n📝 Nhập các passwords (sẽ được mã hóa và lưu an toàn):")
    
    secrets['database_password'] = getpass.getpass("Database password: ")
    secrets['redis_password'] = getpass.getpass("Redis password: ")
    secrets['jwt_secret'] = secret_manager._generate_jwt_key()
    
    print("\n🔑 Generating crypto keys...")
    secrets['dilithium_master_key'] = secret_manager._generate_dilithium_key()
    secrets['ibe_master_key'] = secret_manager._generate_ibe_key()
    secrets['database_encryption_key'] = secret_manager._generate_db_key()
    
    print("\n💾 Storing secrets securely...")
    success_count = 0
    for key, value in secrets.items():
        if secret_manager.store_secret(key, value):
            print(f"✅ {key}")
            success_count += 1
        else:
            print(f"❌ {key}")
    
    print(f"\n🎯 Setup completed: {success_count}/{len(secrets)} secrets stored")
    
    if success_count == len(secrets):
        print("✅ All secrets stored successfully!")
        print("\n⚠️  IMPORTANT:")
        print("- Backup your Vault/secrets safely")
        print("- Never commit secrets to git")
        print("- Rotate keys regularly")
    else:
        print("❌ Some secrets failed to store. Check logs.")

if __name__ == "__main__":
    setup_production_secrets()
/root/quantum-secure-commerce/scripts/setup_secrets.sh
#!/bin/bash

echo "🔐 Setting up Quantum Commerce Secrets"
echo "======================================"

# Tạo thư mục secrets
mkdir -p secrets
chmod 700 secrets

# Generate master password nếu chưa có
if [ -z "$MASTER_PASSWORD" ]; then
    echo "⚠️ MASTER_PASSWORD not set in environment"
    echo "Generating random master password..."
    MASTER_PASSWORD=$(openssl rand -base64 32)
    echo "export MASTER_PASSWORD='$MASTER_PASSWORD'" >> ~/.bashrc
    echo "✅ Master password generated and saved to ~/.bashrc"
    echo "🔄 Run: source ~/.bashrc"
fi

# Generate secrets
echo "🔑 Generating cryptographic secrets..."

# JWT Secret
JWT_SECRET=$(openssl rand -base64 32)
echo "export JWT_SECRET_KEY='$JWT_SECRET'" >> .env.local

# Dilithium Master Key  
DILITHIUM_KEY=$(openssl rand -base64 64)
echo "export DILITHIUM_MASTER_KEY='$DILITHIUM_KEY'" >> .env.local

# IBE Master Key
IBE_KEY=$(openssl rand -base64 32)
echo "export IBE_MASTER_KEY='$IBE_KEY'" >> .env.local

# Database password
DB_PASS=$(openssl rand -base64 24)
echo "export DB_PASSWORD='$DB_PASS'" >> .env.local

# Redis password
REDIS_PASS=$(openssl rand -base64 24)
echo "export REDIS_PASSWORD='$REDIS_PASS'" >> .env.local

echo ""
echo "✅ Secrets generated in .env.local"
echo "🔒 Load them with: source .env.local"
echo ""
echo "⚠️ IMPORTANT SECURITY NOTES:"
echo "1. NEVER commit .env.local to git"
echo "2. In production, use environment variables or Vault"
echo "3. Rotate keys every 90 days"
echo "4. Backup encrypted secrets securely"
echo ""
echo "🔄 Next: source .env.local && python main.py"
/root/quantum-secure-commerce/scripts/setup_vault.sh
# scripts/setup_vault.sh
#!/bin/bash
set -e

echo "🔐 Setting up HashiCorp Vault..."

# Set Vault address for commands
export VAULT_ADDR='http://localhost:8200'

# Wait for Vault to be ready
until curl -s http://localhost:8200/v1/sys/health &>/dev/null; do
    echo "Waiting for Vault to be ready..."
    sleep 2
done

echo "✅ Vault is ready!"

# Login with dev root token
docker exec qc_vault vault login -address=http://localhost:8200 myroot

# Enable KV v2 secrets engine (if not exists)
echo "📦 Enabling KV v2 secrets engine..."
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault secrets enable -version=2 -path=secret kv 2>/dev/null || echo "KV v2 already enabled"

# Create quantum-commerce path
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault kv put secret/quantum-commerce/config \
    initialized=true \
    timestamp="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# Generate and store master keys
echo "🔑 Generating master keys..."

# IBE Master Key
IBE_KEY=$(openssl rand -base64 32)
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault kv put secret/quantum-commerce/ibe_master_key \
    value="$IBE_KEY"

# Dilithium Master Key  
DILITHIUM_KEY=$(openssl rand -base64 64)
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault kv put secret/quantum-commerce/dilithium_master_key \
    value="$DILITHIUM_KEY"

# Database Encryption Key
DB_KEY=$(python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault kv put secret/quantum-commerce/database_encryption_key \
    value="$DB_KEY"

# JWT Secret
JWT_SECRET=$(openssl rand -base64 32)
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault kv put secret/quantum-commerce/jwt_secret_key \
    value="$JWT_SECRET"

echo "✅ Master keys generated and stored in Vault"

# Verify keys were stored
echo ""
echo "📋 Verifying stored secrets..."
docker exec -e VAULT_ADDR=http://localhost:8200 qc_vault vault kv list secret/quantum-commerce

echo ""
echo "✅ Vault setup completed!"
echo ""
echo "📝 Important information:"
echo "   Vault Address: http://localhost:8200"
echo "   Root Token: myroot"
echo "   Keys are stored at: secret/quantum-commerce/*"
/root/quantum-secure-commerce/scripts/setup.sh
#!/bin/bash

# Quantum-Secure E-Commerce Setup Script - Fixed Version
set -e

echo "🔐 Quantum-Secure E-Commerce Setup (Fixed)"
echo "=========================================="

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

# Check Python version
echo -e "${YELLOW}Checking Python version...${NC}"
python_version=$(python3 --version 2>&1 | awk '{print $2}')
echo -e "${GREEN}✓ Python $python_version is installed${NC}"

# Install system dependencies first
echo -e "${YELLOW}Installing system dependencies...${NC}"
if [[ "$OSTYPE" == "linux-gnu"* ]]; then
    # Check if running on Ubuntu/Debian
    if command -v apt-get &> /dev/null; then
        sudo apt-get update
        sudo apt-get install -y \
            build-essential \
            python3-dev \
            postgresql-client \
            libpq-dev \
            cmake \
            gcc \
            g++ \
            libssl-dev \
            libffi-dev
        echo -e "${GREEN}✓ System dependencies installed${NC}"
    else
        echo -e "${YELLOW}⚠️  Non-Debian system detected. Please install PostgreSQL development files manually.${NC}"
    fi
elif [[ "$OSTYPE" == "darwin"* ]]; then
    # macOS
    if command -v brew &> /dev/null; then
        brew install postgresql cmake openssl
        echo -e "${GREEN}✓ System dependencies installed${NC}"
    else
        echo -e "${YELLOW}⚠️  Homebrew not found. Please install dependencies manually.${NC}"
    fi
fi

# Create virtual environment
echo -e "${YELLOW}Creating virtual environment...${NC}"
python3 -m venv venv
source venv/bin/activate
echo -e "${GREEN}✓ Virtual environment created${NC}"

# Upgrade pip and install wheel
echo -e "${YELLOW}Upgrading pip and installing wheel...${NC}"
pip install --upgrade pip wheel setuptools
echo -e "${GREEN}✓ Pip upgraded${NC}"

# Try to install psycopg2-binary first
echo -e "${YELLOW}Installing psycopg2-binary...${NC}"
pip install psycopg2-binary==2.9.9 || {
    echo -e "${YELLOW}Failed to install psycopg2-binary, trying alternative...${NC}"
    pip install psycopg[binary]==3.1.12
}
echo -e "${GREEN}✓ PostgreSQL adapter installed${NC}"

# Install other requirements
echo -e "${YELLOW}Installing other requirements...${NC}"
# Create a temporary requirements file without psycopg2-binary
grep -v "psycopg2-binary" requirements.txt > temp_requirements.txt
pip install -r temp_requirements.txt
rm temp_requirements.txt
echo -e "${GREEN}✓ Base requirements installed${NC}"

# Create directory structure
echo -e "${YELLOW}Creating directory structure...${NC}"
mkdir -p {config,crypto,services,models,api,database/migrations,webapp/{public,src/{components,pages,services}},scripts,tests,keys/{ibe,dilithium},logs,nginx/ssl}

# Create necessary Python files to avoid import errors
touch config/__init__.py crypto/__init__.py services/__init__.py models/__init__.py api/__init__.py database/__init__.py

echo -e "${GREEN}✓ Directory structure created${NC}"

# Create .env file if not exists
if [ ! -f .env ]; then
    echo -e "${YELLOW}Creating .env file...${NC}"
    cat > .env << EOL
# Database
DB_USER=qsc_user
DB_PASSWORD=secure_password_change_me
DB_NAME=quantum_commerce
DB_HOST=localhost
DB_PORT=5432

# Redis
REDIS_PASSWORD=redis_secure_pass_change_me
REDIS_HOST=localhost
REDIS_PORT=6379

# Security
SECRET_KEY=$(python3 -c 'import secrets; print(secrets.token_urlsafe(32))')
JWT_SECRET_KEY=$(python3 -c 'import secrets; print(secrets.token_urlsafe(32))')

# Crypto
IBE_MASTER_PASSWORD=secure_master_password_change_me
DILITHIUM_KEY_PASSWORD=secure_key_password_change_me

# API
API_HOST=0.0.0.0
API_PORT=8000
ENVIRONMENT=development

# Frontend
REACT_APP_API_URL=http://localhost:8000
EOL
    echo -e "${GREEN}✓ .env file created${NC}"
    echo -e "${YELLOW}⚠️  Please update the passwords in .env file!${NC}"
fi

# Create the main.py file if it doesn't exist
if [ ! -f main.py ]; then
    echo -e "${YELLOW}Creating main.py...${NC}"
    echo "# Main API file will be created here" > main.py
fi

# Try to install liboqs-python (optional, may fail)
echo -e "${YELLOW}Attempting to install liboqs-python...${NC}"
pip install git+https://github.com/open-quantum-safe/liboqs-python.git 2>/dev/null || {
    echo -e "${YELLOW}⚠️  liboqs-python installation failed. The app will use fallback encryption.${NC}"
    echo -e "${YELLOW}   To use quantum-safe crypto, install liboqs manually later.${NC}"
}

# Create simplified init_crypto.py
cat > scripts/init_crypto.py << 'EOL'
#!/usr/bin/env python3
"""Initialize cryptographic systems - Simplified version"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

print("Crypto initialization will be done when starting the app...")
print("✓ Crypto setup script created")
EOL

chmod +x scripts/init_crypto.py

# Summary
echo -e "\n${GREEN}========================================${NC}"
echo -e "${GREEN}✓ Setup completed!${NC}"
echo -e "${GREEN}========================================${NC}"

echo -e "\n${YELLOW}Next steps:${NC}"
echo -e "1. Copy the crypto files to the crypto directory:"
echo -e "   ${GREEN}cp /path/to/ibe_system.py crypto/${NC}"
echo -e "   ${GREEN}cp /path/to/dilithium_signer.py crypto/${NC}"
echo -e ""
echo -e "2. Copy the services files:"
echo -e "   ${GREEN}cp /path/to/payment_service.py services/${NC}"
echo -e ""
echo -e "3. Copy the main.py file:"
echo -e "   ${GREEN}cp /path/to/main.py ./${NC}"
echo -e ""
echo -e "4. Update passwords in ${YELLOW}.env${NC} file"
echo -e ""
echo -e "5. Start PostgreSQL and Redis using Docker:"
echo -e "   ${GREEN}docker-compose up -d postgres redis${NC}"
echo -e ""
echo -e "6. Run the API:"
echo -e "   ${GREEN}source venv/bin/activate${NC}"
echo -e "   ${GREEN}python main.py${NC}"

echo -e "\n${YELLOW}Optional: For full quantum-safe features:${NC}"
echo -e "- Install liboqs: ${GREEN}sudo apt-get install liboqs-dev${NC}"
echo -e "- Then: ${GREEN}pip install git+https://github.com/open-quantum-safe/liboqs-python.git${NC}"

/root/quantum-secure-commerce/secrets/.master.key
LLvaerAhX_I6XE5CySGH6pNCL6HmibamJDIJ3X1jnVg=
/root/quantum-secure-commerce/secrets/encrypted_secrets.json
{"jwt_secret": "gAAAAABoRm95UJDKATDZhHnTKGW4e8NnCgf-STNbxLgWiwjDelp_CFR5QyygHq2H_VUfgqLje_2WesKBW_j0qjcgOnU3Og3ud2cW8kk_7gnREpiSW7vpv-Yra2vC3vjPJt7VTcCNoMoL", "dilithium_master_key": "gAAAAABoRm95OeeeafaY2CsGcQqtY-1iWJ-NQLkkSUIzxL5jmIwY_-tx-jZp4wdTBhiE1eCwi6ZMNASk4ZjGXR54ioksH5nwSX38BcYzgsnSNE5UmTIYQZZOSeCLbLL0YSYDwCBjS8d4k2kWLhuDKYe2fqtuvsMQsNWa_qN1OHm33Tf4VmIQu80NYlgaJ-CZ8lzHxi0fxWcc", "ibe_master_key": "gAAAAABoRm95hxwvgQemajn2OX0KrwFz7oH2RmLIfK079-NmrK4E_RPZUU-MwGkVKHrjHy4IJ1e6gvVKJHEByRygW5_phPBUN4xO9HC5LzVNhIM5k6vt2z-FU_2tzq_cm5SLSI29PH5R", "database_encryption_key": "gAAAAABoRlVwvCoQGlQfjSI_oT3QStmAGk58IUgvloe6riR0IHoq57b-H-eWPkYIdN5Zas6vRbrpCb2lhfqv6PkYKxUqtr4XFXaXntx8p7lAr8oYzORDTLDKn5ke_qEof6yQ5jcBjk-B", "database_password": "gAAAAABoRm955iDJKUvxHPxZ-ynLnoTZvy6X7tkhwBEx1edi7uu8nlUgIEMdOF9616z13U0YWaQKLX7LDWpOKz9a__jB_nsUOw==", "redis_password": "gAAAAABoRm95gerWJKIcaSdAaop7ULmDuRZBnI9AGnIoXuF5sO_DaQSoaBi_r5fXyTAVcVsI5R0xS9Li-EfA5v7yB4Wbn4ue7A=="}
/root/quantum-secure-commerce/secrets/salt.dat
Có mà mã hóa rồi nên mình ko gửi

/root/quantum-secure-commerce/security/incident_response.py
# security/incident_response.py
"""
SECURITY INCIDENT RESPONSE SYSTEM
Tự động phát hiện và response các security incidents
"""
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from enum import Enum
import asyncio

logger = logging.getLogger(__name__)

class IncidentSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium" 
    HIGH = "high"
    CRITICAL = "critical"

class IncidentType(Enum):
    UNAUTHORIZED_ACCESS = "unauthorized_access"
    CRYPTO_ATTACK = "crypto_attack"
    DATA_BREACH = "data_breach"
    KEY_COMPROMISE = "key_compromise"
    REPLAY_ATTACK = "replay_attack"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    SUSPICIOUS_ACTIVITY = "suspicious_activity"
    SYSTEM_COMPROMISE = "system_compromise"

class SecurityIncident:
    """Security incident object"""
    
    def __init__(self, incident_type: IncidentType, severity: IncidentSeverity, 
                 description: str, source_ip: str = None, user_id: str = None):
        self.id = f"INC_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{hash(description) % 10000:04d}"
        self.incident_type = incident_type
        self.severity = severity
        self.description = description
        self.source_ip = source_ip
        self.user_id = user_id
        self.timestamp = datetime.utcnow()
        self.status = "open"
        self.response_actions = []
        self.resolved_at = None

class IncidentResponseSystem:
    """Automated security incident response"""
    
    def __init__(self):
        self.incidents = {}  # In production: use database
        self.response_rules = self._load_response_rules()
        self.notification_config = self._load_notification_config()
        
    def _load_response_rules(self) -> Dict[str, Any]:
        """Load automated response rules"""
        return {
            IncidentType.UNAUTHORIZED_ACCESS: {
                'auto_actions': ['block_ip', 'invalidate_sessions', 'alert_admin'],
                'escalation_time_minutes': 15,
                'requires_manual_review': True
            },
            IncidentType.CRYPTO_ATTACK: {
                'auto_actions': ['emergency_key_rotation', 'block_ip', 'alert_security_team'],
                'escalation_time_minutes': 5,
                'requires_manual_review': True
            },
            IncidentType.DATA_BREACH: {
                'auto_actions': ['isolate_systems', 'emergency_key_rotation', 'notify_authorities'],
                'escalation_time_minutes': 1,
                'requires_manual_review': True
            },
            IncidentType.KEY_COMPROMISE: {
                'auto_actions': ['emergency_key_rotation', 'invalidate_all_sessions', 'alert_security_team'],
                'escalation_time_minutes': 2,
                'requires_manual_review': True
            },
            IncidentType.REPLAY_ATTACK: {
                'auto_actions': ['block_ip', 'invalidate_session', 'alert_admin'],
                'escalation_time_minutes': 10,
                'requires_manual_review': False
            },
            IncidentType.RATE_LIMIT_EXCEEDED: {
                'auto_actions': ['temporary_ip_block', 'alert_admin'],
                'escalation_time_minutes': 30,
                'requires_manual_review': False
            }
        }
    
    def _load_notification_config(self) -> Dict[str, Any]:
        """Load notification configuration"""
        return {
            'security_team_email': ['security@quantum-commerce.com'],
            'admin_email': ['admin@quantum-commerce.com'],
            'slack_security_channel': '#security-alerts',
            'pagerduty_integration': True,
            'sms_alerts': ['+1234567890']  # For critical incidents
        }
    
    async def report_incident(self, incident_type: IncidentType, severity: IncidentSeverity,
                            description: str, context: Dict[str, Any] = None) -> SecurityIncident:
        """Report và process security incident"""
        
        # Create incident
        incident = SecurityIncident(
            incident_type=incident_type,
            severity=severity,
            description=description,
            source_ip=context.get('source_ip') if context else None,
            user_id=context.get('user_id') if context else None
        )
        
        # Store incident
        self.incidents[incident.id] = incident
        
        logger.critical(f"🚨 SECURITY INCIDENT: {incident.id} - {incident.incident_type.value}")
        logger.critical(f"   Severity: {incident.severity.value}")
        logger.critical(f"   Description: {incident.description}")
        
        # Trigger automated response
        await self._trigger_automated_response(incident, context)
        
        # Send notifications
        await self._send_incident_notifications(incident)
        
        return incident
    
    async def _trigger_automated_response(self, incident: SecurityIncident, context: Dict[str, Any] = None):
        """Trigger automated response actions"""
        
        rules = self.response_rules.get(incident.incident_type)
        if not rules:
            logger.warning(f"No response rules for {incident.incident_type.value}")
            return
        
        logger.warning(f"🤖 Triggering automated response for {incident.id}")
        
        for action in rules['auto_actions']:
            try:
                success = await self._execute_response_action(action, incident, context)
                
                incident.response_actions.append({
                    'action': action,
                    'timestamp': datetime.utcnow().isoformat(),
                    'success': success,
                    'automated': True
                })
                
                if success:
                    logger.info(f"✅ Executed response action: {action}")
                else:
                    logger.error(f"❌ Failed response action: {action}")
                    
            except Exception as e:
                logger.error(f"❌ Response action {action} failed: {e}")
    
    async def _execute_response_action(self, action: str, incident: SecurityIncident, 
                                     context: Dict[str, Any] = None) -> bool:
        """Execute specific response action"""
        
        try:
            if action == 'block_ip':
                return await self._block_ip(incident.source_ip)
            
            elif action == 'temporary_ip_block':
                return await self._temporary_ip_block(incident.source_ip, minutes=30)
            
            elif action == 'invalidate_sessions':
                return await self._invalidate_user_sessions(incident.user_id)
            
            elif action == 'invalidate_all_sessions':
                return await self._invalidate_all_sessions()
            
            elif action == 'emergency_key_rotation':
                return await self._emergency_key_rotation(incident.description)
            
            elif action == 'isolate_systems':
                return await self._isolate_affected_systems(context)
            
            elif action == 'alert_admin':
                return await self._alert_administrators(incident)
            
            elif action == 'alert_security_team':
                return await self._alert_security_team(incident)
            
            elif action == 'notify_authorities':
                return await self._notify_authorities(incident)
            
            else:
                logger.warning(f"Unknown response action: {action}")
                return False
                
        except Exception as e:
            logger.error(f"Response action {action} error: {e}")
            return False
    
    async def _block_ip(self, ip_address: str) -> bool:
        """Block IP address permanently"""
        if not ip_address:
            return False
        
        # In production: update firewall rules, WAF, etc.
        logger.warning(f"🚫 BLOCKING IP: {ip_address}")
        
        # Add to blocked IPs list
        from security.security_middleware import security_middleware
        security_middleware.suspicious_ips.add(ip_address)
        
        return True
    
    async def _temporary_ip_block(self, ip_address: str, minutes: int = 30) -> bool:
        """Temporarily block IP address"""
        if not ip_address:
            return False
        
        logger.warning(f"⏰ TEMPORARY BLOCK: {ip_address} for {minutes} minutes")
        
        # Implementation: temporary block logic
        # Could use Redis with TTL
        
        return True
    
    async def _invalidate_user_sessions(self, user_id: str) -> bool:
        """Invalidate all sessions for specific user"""
        if not user_id:
            return False
        
        logger.warning(f"🔓 INVALIDATING SESSIONS for user: {user_id}")
        
        try:
            from services.session_service import session_service
            count = session_service.destroy_all_user_sessions(int(user_id))
            logger.info(f"✅ Invalidated {count} sessions for user {user_id}")
            return True
        except Exception as e:
            logger.error(f"Session invalidation failed: {e}")
            return False
    
    async def _invalidate_all_sessions(self) -> bool:
        """Invalidate ALL active sessions (nuclear option)"""
        logger.critical("☢️  INVALIDATING ALL SESSIONS (NUCLEAR OPTION)")
        
        try:
            from services.session_service import session_service
            # Implementation: clear all session keys from Redis
            # session_service.redis_client.flushdb()
            
            logger.critical("✅ All sessions invalidated")
            return True
        except Exception as e:
            logger.error(f"Failed to invalidate all sessions: {e}")
            return False
    
    async def _emergency_key_rotation(self, reason: str) -> bool:
        """Emergency rotation of all cryptographic keys"""
        logger.critical(f"🔄 EMERGENCY KEY ROTATION: {reason}")
        
        try:
            from scripts.key_rotation import KeyRotationManager
            rotation_manager = KeyRotationManager()
            await rotation_manager.emergency_rotate_all_keys(reason)
            return True
        except Exception as e:
            logger.error(f"Emergency key rotation failed: {e}")
            return False
    
    async def _isolate_affected_systems(self, context: Dict[str, Any] = None) -> bool:
        """Isolate affected systems from network"""
        logger.critical("🏝️ ISOLATING AFFECTED SYSTEMS")
        
        # Implementation would:
        # 1. Identify affected containers/services
        # 2. Remove from load balancer
        # 3. Block network access
        # 4. Create isolated environment for forensics
        
        return True
    
    async def _alert_administrators(self, incident: SecurityIncident) -> bool:
        """Alert system administrators"""
        message = f"""
🚨 SECURITY ALERT - {incident.severity.value.upper()}

Incident ID: {incident.id}
Type: {incident.incident_type.value}
Time: {incident.timestamp}
Description: {incident.description}
Source IP: {incident.source_ip or 'N/A'}
User ID: {incident.user_id or 'N/A'}

Immediate actions taken:
{chr(10).join([f"- {action['action']}" for action in incident.response_actions])}

Please review and take additional action if needed.
        """
        
        # Send email/slack notifications
        await self._send_notification(message, self.notification_config['admin_email'])
        return True
    
    async def _alert_security_team(self, incident: SecurityIncident) -> bool:
        """Alert security team"""
        message = f"""
🚨 CRITICAL SECURITY INCIDENT

ID: {incident.id}
Severity: {incident.severity.value.upper()}
Type: {incident.incident_type.value}
Time: {incident.timestamp}

{incident.description}

Automated response triggered. Manual review required.
        """
        
        # Send to security team
        await self._send_notification(message, self.notification_config['security_team_email'])
        
        # Send SMS for critical incidents
        if incident.severity == IncidentSeverity.CRITICAL:
            await self._send_sms_alert(message)
        
        return True
    
    async def _notify_authorities(self, incident: SecurityIncident) -> bool:
        """Notify authorities for data breaches"""
        logger.critical("🏛️ NOTIFYING AUTHORITIES - DATA BREACH")
        
        # Implementation would:
        # 1. Prepare incident report
        # 2. Send to regulatory bodies (GDPR, etc.)
        # 3. Notify law enforcement if required
        # 4. Document all communications
        
        return True
    
    async def _send_notification(self, message: str, recipients: List[str]):
        """Send notification via email/slack"""
        logger.info(f"📨 Sending notification to {len(recipients)} recipients")
        # Implementation: actual email/slack sending
    
    async def _send_sms_alert(self, message: str):
        """Send SMS alert for critical incidents"""
        logger.info("📱 Sending SMS alert")
        # Implementation: SMS gateway integration
    
    async def _send_incident_notifications(self, incident: SecurityIncident):
        """Send notifications based on incident severity"""
        
        if incident.severity in [IncidentSeverity.CRITICAL, IncidentSeverity.HIGH]:
            await self._alert_security_team(incident)
        
        if incident.severity == IncidentSeverity.CRITICAL:
            # Page security team immediately
            logger.critical(f"📟 PAGING SECURITY TEAM - {incident.id}")
        
        # Always alert admins
        await self._alert_administrators(incident)
    
    def get_incident_statistics(self, days: int = 30) -> Dict[str, Any]:
        """Get incident statistics"""
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        
        recent_incidents = [
            inc for inc in self.incidents.values()
            if inc.timestamp >= cutoff_date
        ]
        
        stats = {
            'total_incidents': len(recent_incidents),
            'by_severity': {},
            'by_type': {},
            'resolved_count': 0,
            'avg_resolution_time_hours': 0
        }
        
        # Count by severity
        for severity in IncidentSeverity:
            count = len([inc for inc in recent_incidents if inc.severity == severity])
            stats['by_severity'][severity.value] = count
        
        # Count by type
        for incident_type in IncidentType:
            count = len([inc for inc in recent_incidents if inc.incident_type == incident_type])
            stats['by_type'][incident_type.value] = count
        
        # Resolution stats
        resolved = [inc for inc in recent_incidents if inc.resolved_at]
        stats['resolved_count'] = len(resolved)
        
        if resolved:
            total_resolution_time = sum([
                (inc.resolved_at - inc.timestamp).total_seconds() / 3600
                for inc in resolved
            ])
            stats['avg_resolution_time_hours'] = total_resolution_time / len(resolved)
        
        return stats
    
    async def resolve_incident(self, incident_id: str, resolution_notes: str):
        """Mark incident as resolved"""
        if incident_id in self.incidents:
            incident = self.incidents[incident_id]
            incident.status = "resolved"
            incident.resolved_at = datetime.utcnow()
            
            logger.info(f"✅ Incident {incident_id} resolved: {resolution_notes}")
            
            # Send resolution notification
            await self._send_resolution_notification(incident, resolution_notes)

    async def _send_resolution_notification(self, incident: SecurityIncident, notes: str):
        """Send incident resolution notification"""
        message = f"""
✅ INCIDENT RESOLVED

ID: {incident.id}
Type: {incident.incident_type.value}
Resolved: {incident.resolved_at}
Resolution: {notes}

Total duration: {incident.resolved_at - incident.timestamp}
        """
        
        await self._send_notification(message, self.notification_config['admin_email'])

# Global incident response system
incident_response = IncidentResponseSystem()

# Convenience functions for common incidents
async def report_unauthorized_access(source_ip: str, user_id: str = None, details: str = ""):
    """Report unauthorized access attempt"""
    return await incident_response.report_incident(
        IncidentType.UNAUTHORIZED_ACCESS,
        IncidentSeverity.HIGH,
        f"Unauthorized access attempt: {details}",
        {'source_ip': source_ip, 'user_id': user_id}
    )

async def report_crypto_attack(attack_type: str, source_ip: str = None, details: str = ""):
    """Report cryptographic attack"""
    return await incident_response.report_incident(
        IncidentType.CRYPTO_ATTACK,
        IncidentSeverity.CRITICAL,
        f"Crypto attack detected: {attack_type} - {details}",
        {'source_ip': source_ip}
    )

async def report_data_breach(affected_users: int, data_types: List[str], details: str = ""):
    """Report data breach"""
    return await incident_response.report_incident(
        IncidentType.DATA_BREACH,
        IncidentSeverity.CRITICAL,
        f"Data breach: {affected_users} users affected, data: {', '.join(data_types)} - {details}",
        {'affected_users': affected_users, 'data_types': data_types}
    )

# CLI for incident management
async def main():
    """CLI for incident management"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Security Incident Response')
    parser.add_argument('action', choices=['list', 'stats', 'resolve', 'test'])
    parser.add_argument('--incident-id', help='Incident ID for resolution')
    parser.add_argument('--notes', help='Resolution notes')
    parser.add_argument('--days', type=int, default=

/root/quantum-secure-commerce/security/security_middleware.py
# security/security_middleware.py
"""
Enhanced Security Middleware Stack
"""
import time
import json
import hashlib
from typing import Dict, Any, Optional
from fastapi import Request, HTTPException, status
from fastapi.security import HTTPBearer
from datetime import datetime, timezone
import logging

logger = logging.getLogger(__name__)

class SecurityEnhancements:
    """Enhanced security middleware stack"""
    
    def __init__(self):
        self.rate_limits = {}
        self.suspicious_ips = set()
        self.failed_attempts = {}
        
    async def security_middleware(self, request: Request, call_next):
        """Comprehensive security middleware"""
        
        # 1. Get client info
        client_ip = self._get_client_ip(request)
        user_agent = request.headers.get("user-agent", "")
        
        # 2. Security checks
        security_result = await self._run_security_checks(request, client_ip, user_agent)
        
        if not security_result["allowed"]:
            logger.warning(f"🚫 Security block: {security_result['reason']} from {client_ip}")
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail=security_result["reason"]
            )
        
        # 3. Add security headers
        response = await call_next(request)
        self._add_security_headers(response)
        
        # 4. Log security event
        await self._log_security_event(request, response, client_ip)
        
        return response
    
    async def _run_security_checks(self, request: Request, client_ip: str, user_agent: str) -> Dict[str, Any]:
        """Run comprehensive security checks"""
        
        # 1. Rate limiting
        if not self._check_rate_limit(client_ip, request.url.path):
            return {"allowed": False, "reason": "Rate limit exceeded"}
        
        # 2. Suspicious IP check
        if client_ip in self.suspicious_ips:
            return {"allowed": False, "reason": "IP blocked for suspicious activity"}
        
        # 3. Bot detection
        if self._detect_bot(user_agent):
            return {"allowed": False, "reason": "Automated traffic detected"}
        
        # 4. Path traversal detection
        if self._detect_path_traversal(str(request.url)):
            self.suspicious_ips.add(client_ip)
            return {"allowed": False, "reason": "Path traversal attempt detected"}
        
        # 5. SQL injection detection (basic)
        if self._detect_sql_injection(str(request.url)):
            self.suspicious_ips.add(client_ip)
            return {"allowed": False, "reason": "SQL injection attempt detected"}
        
        return {"allowed": True, "reason": "Passed security checks"}
    
    def _check_rate_limit(self, client_ip: str, path: str) -> bool:
        """Enhanced rate limiting per IP per endpoint"""
        current_time = time.time()
        
        # Different limits for different endpoints
        limits = {
            "/api/crypto/sign": {"requests": 10, "window": 60},      # 10 signatures per minute
            "/api/crypto/verify": {"requests": 20, "window": 60},    # 20 verifications per minute
            "/api/auth/login": {"requests": 5, "window": 300},       # 5 login attempts per 5 minutes
            "default": {"requests": 100, "window": 60}               # 100 requests per minute
        }
        
        # Get limit for this path
        limit_config = limits.get(path, limits["default"])
        
        # Create rate limit key
        key = f"{client_ip}:{path}"
        
        if key not in self.rate_limits:
            self.rate_limits[key] = []
        
        # Clean old requests
        self.rate_limits[key] = [
            req_time for req_time in self.rate_limits[key]
            if current_time - req_time < limit_config["window"]
        ]
        
        # Check if limit exceeded
        if len(self.rate_limits[key]) >= limit_config["requests"]:
            return False
        
        # Add current request
        self.rate_limits[key].append(current_time)
        return True
    
    def _detect_bot(self, user_agent: str) -> bool:
        """Detect automated/bot traffic"""
        bot_indicators = [
            "bot", "crawler", "spider", "scraper", "curl", "wget",
            "python-requests", "http", "automated", "script"
        ]
        
        ua_lower = user_agent.lower()
        return any(indicator in ua_lower for indicator in bot_indicators)
    
    def _detect_path_traversal(self, url: str) -> bool:
        """Detect path traversal attempts"""
        traversal_patterns = ["../", "..\\", "%2e%2e", "%2f", "%5c"]
        return any(pattern in url.lower() for pattern in traversal_patterns)
    
    def _detect_sql_injection(self, url: str) -> bool:
        """Basic SQL injection detection"""
        sql_patterns = [
            "union select", "drop table", "insert into", "delete from",
            "update set", "or 1=1", "and 1=1", "'; --", "admin'--"
        ]
        return any(pattern in url.lower() for pattern in sql_patterns)
    
    def _get_client_ip(self, request: Request) -> str:
        """Get real client IP considering proxies"""
        # Check various headers for real IP
        forwarded_for = request.headers.get("x-forwarded-for")
        if forwarded_for:
            return forwarded_for.split(",")[0].strip()
        
        real_ip = request.headers.get("x-real-ip")
        if real_ip:
            return real_ip
        
        return request.client.host if request.client else "unknown"
    
    def _add_security_headers(self, response):
        """Add comprehensive security headers"""
        security_headers = {
            "X-Content-Type-Options": "nosniff",
            "X-Frame-Options": "DENY",
            "X-XSS-Protection": "1; mode=block",
            "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
            "Content-Security-Policy": "default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'",
            "Referrer-Policy": "strict-origin-when-cross-origin",
            "Permissions-Policy": "geolocation=(), microphone=(), camera=()",
            "X-Quantum-Secure": "true"  # Custom header
        }
        
        for header, value in security_headers.items():
            response.headers[header] = value
    
    async def _log_security_event(self, request: Request, response, client_ip: str):
        """Log security events for analysis"""
        event = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "client_ip": client_ip,
            "method": request.method,
            "path": str(request.url.path),
            "user_agent": request.headers.get("user-agent", ""),
            "status_code": response.status_code,
            "quantum_endpoint": "/api/crypto/" in str(request.url.path)
        }
        
        # Log to security log file
        logger.info(f"🔒 Security Event: {json.dumps(event)}")

class QuantumSecurityAudit:
    """Audit logging for quantum crypto operations"""
    
    def __init__(self):
        self.audit_log = []
    
    def log_crypto_operation(self, operation: str, user_id: str, details: Dict[str, Any]):
        """Log quantum crypto operations"""
        audit_entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "operation": operation,
            "user_id": user_id,
            "details": details,
            "signature_hash": self._generate_audit_hash(operation, user_id, details)
        }
        
        self.audit_log.append(audit_entry)
        logger.info(f"🛡️ Quantum Audit: {operation} by {user_id}")
    
    def _generate_audit_hash(self, operation: str, user_id: str, details: Dict[str, Any]) -> str:
        """Generate hash for audit integrity"""
        audit_string = f"{operation}:{user_id}:{json.dumps(details, sort_keys=True)}"
        return hashlib.sha256(audit_string.encode()).hexdigest()
    
    def get_audit_trail(self, user_id: Optional[str] = None) -> list:
        """Get audit trail for user or all"""
        if user_id:
            return [entry for entry in self.audit_log if entry["user_id"] == user_id]
        return self.audit_log

# Global instances
security_middleware = SecurityEnhancements()
quantum_audit = QuantumSecurityAudit()

# Enhanced authentication
class QuantumJWTBearer(HTTPBearer):
    """Enhanced JWT bearer with quantum crypto context"""
    
    def __init__(self, auto_error: bool = True):
        super().__init__(auto_error=auto_error)
    
    async def __call__(self, request: Request):
        """Validate JWT with enhanced security"""
        credentials = await super().__call__(request)
        
        if credentials:
            # Enhanced token validation
            token_data = self._validate_token(credentials.credentials)
            
            if not token_data:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="Invalid quantum security token"
                )
            
            # Log authentication event
            quantum_audit.log_crypto_operation(
                "authentication",
                token_data.get("user_id", "unknown"),
                {"token_valid": True, "quantum_context": True}
            )
            
            return token_data
        
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Missing quantum security credentials"
        )
    
    def _validate_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Enhanced token validation"""
        # Implement JWT validation with quantum context
        # For now, return mock data
        return {
            "user_id": "quantum_user_123",
            "quantum_verified": True,
            "security_level": "quantum_secure"
        }

# Export middleware
quantum_jwt = QuantumJWTBearer()

